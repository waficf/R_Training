
> https://discuss.analyticsvidhya.com/t/what-are-the-packages-required-to-plot-a-fancy-rpart-plot-in-r/6776
> http://blog.revolutionanalytics.com/2013/06/plotting-classification-and-regression-trees-with-plotrpart.html
> http://www.cmap.polytechnique.fr/~lepennec/R/Learning/Learning.html
> http://michael.hahsler.net/SMU/EMIS7332/R/viz_classifier.html


```{r}
library(dplyr)
library(ggplot2) # Data visualization
library(GGally) #ggpair
library(ElemStatLearn) # KNN classifier plot
library(rpart) # Fancy decision making plots
library(readr) # CSV file I/O, e.g. the read_csv function
library(tm) # text mining in R
library(knitr) # Convert to html
library(SnowballC) # Removes stemming words
library(wordcloud)
library(tidyverse)
library(gmodels) # Uses crosstab function
library('mice') # imputation
library(VIM)  # Plots missing data
library(gridExtra) #Plotting ggplots side by side
library(ggpubr) # Nice Theme

library(C50) # Package that includes the decision tree algorithm
library(e1071) # Naive Bayes package (naiveBayes)
library(klaR) # Another naive bayes package (NaiveBayes)
library('randomForest') # Random Forest
library(caret) # Splitting data including cross validation
library(class) # KNN Classifier 
```


```{r}
titanic <- read.csv('/Users/wafic/Downloads/data/titanic_data.csv', stringsAsFactors = FALSE, na.strings=c("","NA"))
```

```{r}
dim(titanic)
```

```{r}
nulls <- function(x){
  sum(is.na(x))
}

sapply(titanic, nulls)
```

```{r}
str(titanic)
```

```{r}
data_tit <- subset(titanic, select=-c(Ticket, PassengerId, Cabin))
str(data_tit)
```

```{r}
data_tit$Survived <- factor(data_tit$Survived)
prop.table(table(data_tit$Survived))*100
```

```{r}
prop.table(table(data_tit$Embarked))*100
```

```{r}
prop.table(table(data_tit$Sex))*100
```

```{r}
summary(data_tit$Fare)
```

```{r}
summary(data_tit$Age)
```


```{r}
summary(data_tit)
```


```{r}
ggplot(aes(x=Fare), data=data_tit)+
  geom_histogram()
```

```{r}
ggplot(aes(x=Age), data = data_tit)+
  geom_histogram()
```


```{r}
data_tit$Title <- gsub("(.*, )|(\\..*)", '',data_tit$Name)
table(data_tit$Title, data_tit$Sex)
```

```{r}
rare_titles <- c("Capt", "Col", "Don", "Dr", "Jonkheer", "Lady", "Major", "Rev", "Sir", "the Countess")
data_tit$Title[data_tit$Title == 'Mme'] <- 'Mrs'
data_tit$Title[data_tit$Title == 'Mlle'] <- 'Miss'
data_tit$Title[data_tit$Title == 'Ms'] <- 'Miss'
data_tit$Title[data_tit$Title %in% rare_titles] <- 'Rare'
table(data_tit$Title, data_tit$Sex)
```


```{r}
ggplot(aes(x=Title, fill=factor(Survived)), data=data_tit)+
  geom_bar()+
  theme_classic()
```

```{r}
data_tit$F_Size <-  data_tit$SibSp + data_tit$Parch +1
head(data_tit, 2)
```


```{r}
ggplot(aes(x=F_Size, fill=factor(Survived)),data=data_tit)+
  geom_bar(position = "dodge")+
  xlab("Family Size")+
  theme_pubclean()
```

```{r}
data_tit$F_Size_D[data_tit$F_Size == 1] <- 'Singles'
data_tit$F_Size_D[data_tit$F_Size > 1 & data_tit$F_Size < 5] <- 'Small'
data_tit$F_Size_D[data_tit$F_Size >= 5] <- 'Large'
table(data_tit$F_Size_D, data_tit$Survived)
```


```{r}
mosaicplot(table(data_tit$F_Size_D, data_tit$Survived), main = "Family Survival on the Titanic", color = TRUE, shade=TRUE)
```

# MISSING VALUES

# AGE
```{r}
aggr_plot <- aggr(data_tit, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data_tit), cex.axis=.6, gap=4, ylab=c("Histogram of missing data","Pattern"))
```

```{r}
mice_mod <- mice(data_tit[, !names(data_tit) %in% c('F_Size','Name','Survived')], method='rf',seed=129)
summary(mice_mod)
```

```{r}
mice_output <- complete(mice_mod)
dim(mice_output)
```

```{r}
plot1 <- ggplot(aes(x=Age), data=data_tit)+
  geom_histogram(aes(y = (..density..)), fill='darkgreen', col='white')+
  ylim(0, 0.04)+
  theme_pubclean()

plot2 <- ggplot(aes(x=Age), data=mice_output)+
  geom_histogram(aes(y = (..density..)), fill='lightgreen', col='white')+
  ylim(0, 0.04)+
  theme_pubclean()

grid.arrange(plot1, plot2, ncol=2)
```

```{r}
data_tit$Age <- mice_output$Age
sum(is.na(data_tit$Age))
```

```{r}
ggplot(aes(x=Age, fill= factor(Survived)), data=data_tit)+
  geom_histogram()+
  facet_grid(.~Sex)+
  theme_classic()
```

# EMBARKED

```{r}
which(is.na(data_tit$Embarked), arr.ind=TRUE)
```

```{r}
ggplot(aes(x=Age, y=Fare, colour = factor(Survived), shape=Sex), data=data_tit)+
  geom_point(alpha = 0.8)+
  facet_grid(Pclass~Embarked)+
  scale_y_log10()
```

```{r}
# Looking at the above plot we see they are in class 1, and it makes sense to 
# either put them in S or Q

data_tit[830,]$Fare;data_tit[62,]$Fare
```


```{r}
# They both paid 80
data_embark <- data_tit[-c(62, 830),]

median(data_embark[data_embark$Pclass == 1 & data_embark$Embarked == 'C',]$Fare);median(data_embark[data_embark$Pclass == 1 & data_embark$Embarked == 'S',]$Fare)
```
> Since the median of C is closer to what they paid we will put them in C

```{r}
ggplot(aes(x=Embarked, y=Fare, fill=factor(Pclass)), data=data_embark)+
  geom_boxplot()+
  geom_hline(aes(yintercept=80),colour='red', linetype='dashed', lwd=2)
```


```{r}
# Putting C in these null data points

data_tit$Embarked[c(62, 830)] <- 'C'
```


```{r}
sapply(data_tit, nulls)
```


# FEATURE ENGINEERING

```{r}
data_tit$Child[data_tit$Age < 18] <- 'Child'
data_tit$Child[data_tit$Age >= 18] <- 'Adult'
table(data_tit$Child, data_tit$Survived)
```

```{r}
ggplot(aes(x=Age, fill=factor(Survived)), data=data_tit)+
  geom_histogram()+
  facet_grid(.~Child)
```

```{r}
data_tit$Mother <- 'Not Mother'
data_tit$Mother[data_tit$Child == 'Adult' & data_tit$Sex == 'female' & data_tit$Parch > 0 & data_tit$Title != 'Miss'] <- 'Mother'

table(data_tit$Mother, data_tit$Survived)
```

```{r}
data_tit$Child <- factor(data_tit$Child)
data_tit$Mother <- factor(data_tit$Mother)
```



```{r}
data_tit <- data_tit[-3]
data_tit <- data_tit[-9]
data_tit$Pclass <- factor(data_tit$Pclass)
data_tit$Sex <- factor(data_tit$Sex)
data_tit$Embarked <- factor(data_tit$Embarked)
data_tit$Title <- factor(data_tit$Title)
data_tit$F_Size_D <- factor(data_tit$F_Size_D)
str(data_tit)
```

```{r, message=FALSE, warning=FALSE}
multi_plot <- data_tit[, c('Survived', 'Pclass', 'Sex', 'Age', 'Embarked', 'Fare', 'Title', 'F_Size_D')]
ggpairs(multi_plot, columns = 1:ncol(multi_plot), title = "Multi_Plots",axisLabels = "show", columnLabels = colnames(multi_plot[, columns]))
```


```{r}
md.pattern(data_tit)
```

```{r}
# Selecting which variables are most important
model.tree  <- train(Survived ~ .,
                   data = data_tit,
                   method = "rpart")

plot(varImp(model.tree), top = 10)
```


```{r}
# Splitting the data
split = 0.8
trainIndex <- createDataPartition(data_tit$Survived, p=split, list=FALSE)
train <- data_tit[trainIndex,]
test <- data_tit[-trainIndex,]

train_labels <- data_tit[trainIndex,]$Survived
test_labels <- data_tit[-trainIndex,]$Survived
```


```{r}
# K-NN Classifier
ctr <- trainControl(method="repeatedcv",number =10 ,repeats = 3)

knn_classifier <- train(Survived ~ ., data = train, method = "knn", trControl = ctr, preProcess = c("center","scale"), tuneLength = 20, na.action="na.omit")

knn_classifier;summary(knn_classifier)
```

```{r}
plot(knn_classifier)
```


```{r}
knn_predict <- predict(knn_classifier, newdata = test)
knn_table <- table(actualclass=test_labels, predictedclass=knn_predict)
knn_conf_matrix <- confusionMatrix(knn_table)
print(knn_conf_matrix);CrossTable(knn_predict, test_labels, 
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))
```

```{r}
# Naive Bayes Classifier

naive_classifier <- naiveBayes(train, train_labels)
naive_predictor <- predict(naive_classifier, test)

nb_table <- table(actualclass=test_labels, predictedclass=naive_predictor)
nb_conf_matrix <- confusionMatrix(nb_table)
print(nb_conf_matrix); CrossTable(naive_predictor, test_labels, 
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))
```

```{r}
# Decision Tree
tree_classifier <- C5.0(train[-1], train$Survived)
tree_predictor <- predict(tree_classifier, test)

tree_table <- table(actualclass=test_labels, predictedclass=tree_predictor)
tree_conf_matrix <- confusionMatrix(tree_table)
print(tree_conf_matrix); CrossTable(tree_predictor, test_labels, 
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))
```

```{r}
str(data_tit)
```


```{r}
#https://discuss.analyticsvidhya.com/t/what-are-the-packages-required-to-plot-a-fancy-rpart-plot-in-r/6776/2
rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + F_Size_D, data=data_tit, method="anova")
```


> FInished all 3 algorithms, go through book to see what can be done to enhance 
the performace and then 

